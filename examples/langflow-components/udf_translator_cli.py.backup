#!/usr/bin/env python3
"""
CLI for UDF-based Langflow to StepFlow translator.
Updated to use new parsing functions and generate workflows compatible 
with langflow_component_server_udf_only.py
"""

import argparse
import json
import yaml
from pathlib import Path
from typing import Dict, Any, List


# Add the parsing functions from the new translator
def _build_dependency_graph(edges: List[Dict[str, Any]]) -> Dict[str, List[str]]:
    """Build a dependency graph from Langflow edges."""
    dependencies = {}
    
    for edge in edges:
        source = edge.get('source')
        target = edge.get('target')
        
        if source and target:
            if target not in dependencies:
                dependencies[target] = []
            dependencies[target].append(source)
    
    return dependencies


def _map_langflow_type_to_json_schema(langflow_type: str) -> str:
    """Map Langflow field types to JSON schema types."""
    type_mapping = {
        'str': 'string',
        'int': 'integer', 
        'float': 'number',
        'bool': 'boolean',
        'list': 'array',
        'dict': 'object',
        'dropdown': 'string',
        'slider': 'number',
        'file': 'string',
        'code': 'string',
        'prompt': 'string',
        'multiline': 'string'
    }
    return type_mapping.get(langflow_type, 'string')


def _generate_input_schema_from_template(template: Dict[str, Any]) -> Dict[str, Any]:
    """Generate JSON schema from Langflow template, filtering out UI-only fields."""
    
    # Fields that are UI-only and not needed for execution
    # TODO: FRAZ - obviously this needs help
    ui_only_fields = {
        'advanced', 'dynamic', 'placeholder', 'background_color', 'chat_icon', 
        'text_color', 'icon', 'display_name', 'description', 'info', 'required',
        'load_from_db', 'list', 'show', 'multiline', 'password', 'refresh_button',
        'file_types', 'input_types', 'output_types', 'base_classes', 'documentation',
        'frozen', 'trace_as_metadata', 'trace_as_input', 'files', 'session_id',
        'should_store_message', 'sender', 'sender_name'
    }
    
    properties = {}
    required = []
    
    for field_name, field_config in template.items():
        if field_name == '_type' or not isinstance(field_config, dict):
            continue
            
        # Skip UI-only fields
        if field_name in ui_only_fields:
            continue
            
        # Skip advanced fields that are UI-only
        if field_config.get('advanced', False) and field_name in {
            'background_color', 'chat_icon', 'text_color', 'files', 'session_id',
            'should_store_message', 'sender', 'sender_name'
        }:
            continue
            
        field_type = field_config.get('type', 'str')
        field_required = field_config.get('required', False)
        field_info = field_config.get('info', '')
        
        # Only include fields that have execution relevance
        # Core execution fields for most components
        # TODO: FRAZ - obviously this needs help
        if field_name in {'input_value', 'template', 'model_name', 'temperature', 'api_key', 'context', 'question'}:
            
            # Map Langflow types to JSON schema types
            json_type = _map_langflow_type_to_json_schema(field_type)
            
            property_def = {
                'type': json_type,
                'description': field_info
            }
            
            # Handle specific field configurations
            if field_type == 'dropdown':
                options = field_config.get('options', [])
                if options:
                    property_def['enum'] = options
            elif field_type == 'slider':
                range_spec = field_config.get('range_spec', {})
                if 'min' in range_spec:
                    property_def['minimum'] = range_spec['min']
                if 'max' in range_spec:
                    property_def['maximum'] = range_spec['max']
            
            properties[field_name] = property_def
            
            if field_required:
                required.append(field_name)
    
    return {
        'type': 'object',
        'properties': properties,
        'required': required
    }

def _filter_template_for_execution(template: Dict[str, Any]) -> Dict[str, Any]:
    """Filter template to only include execution-critical fields and values."""
    
    # Core execution fields that components actually need
    # Note: Excluding 'code' since it's handled separately as the main UDF code field
    execution_fields = {
        'input_value', 'template', 'model_name', 'temperature', 'api_key', 
        'context', 'question', 'max_tokens', 'stream', 'system_message',
        'prompt', 'text', 'data', 'embedding_model', 'search_kwargs'
    }
    
    filtered_template = {}
    
    for field_name, field_config in template.items():
        if field_name.startswith('_'):
            continue
            
        # Include ALL execution-critical fields, even if they have empty values
        # Components need to know about all their parameters to handle defaults/env vars
        if field_name in execution_fields and isinstance(field_config, dict):
            value = field_config.get('value')
            
            # Always include execution-critical fields - let the component handle empty values
            filtered_template[field_name] = {'value': value}
    
    return filtered_template


def _filter_outputs_for_execution(outputs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Filter outputs to only include execution-critical fields."""
    filtered_outputs = []
    
    for output in outputs:
        # Only keep the execution-critical fields
        filtered_output = {}
        
        # Method name is essential for execution
        if 'method' in output:
            filtered_output['method'] = output['method']
        
        # Name might be needed for output routing
        if 'name' in output:
            filtered_output['name'] = output['name']
            
        # Types might be needed for type checking
        if 'types' in output:
            filtered_output['types'] = output['types']
        
        # Skip UI fields like display_name, description, cache, etc.
        
        if filtered_output:  # Only add if we have execution-relevant data
            filtered_outputs.append(filtered_output)
    
    return filtered_outputs


def _extract_class_name_from_code(code: str) -> str:
    """Extract the class name from Langflow component code using AST."""
    if not code:
        raise ValueError("No code provided for class name extraction")
    
    import ast
   
    # Parse the code into an AST
    tree = ast.parse(code)
    
    # Find all class definitions
    for node in ast.walk(tree):
        if isinstance(node, ast.ClassDef):
            # Return the first class name found
            # (Langflow components typically have one main class)
            return node.name
    
    raise ValueError("No class definition found in the provided code")


def _extract_component_info(node_data: Dict[str, Any], node_info: Dict[str, Any]) -> Dict[str, Any]:
    """Extract component information from a Langflow node."""
    template = node_info.get('template', {})
    
    # Extract input schema from template (already filtered)
    input_schema = _generate_input_schema_from_template(template)
    
    # Filter template to only execution-critical fields
    filtered_template = _filter_template_for_execution(template)
    
    # Filter outputs to only execution-critical fields
    filtered_outputs = _filter_outputs_for_execution(node_info.get('outputs', []))
    
    # Extract the component type and configuration
    component_type = node_data.get('type', 'unknown')
    
    # Get the original component code if available
    original_code = template.get('code', {}).get('value', '') if 'code' in template else ''
    
    # Extract the actual class name from the code (if code exists)
    if original_code:
        try:
            actual_class_name = _extract_class_name_from_code(original_code)
            if actual_class_name:
                component_type = actual_class_name  # Use the actual class name instead of the Langflow type
        except ValueError:
            # No class found in code, use the original component_type
            pass
    
    # Get the selected output method - this helps determine which method to execute
    selected_output = node_data.get('selected_output')
    
    # If no selected_output is specified, use the first output as default
    # This is the case for output nodes, possibly(? or maybe just chat output) 
    if not selected_output and filtered_outputs:
        selected_output = filtered_outputs[0].get('name')
        print(f"No selected_output for {component_type}, using first output: {selected_output}")
    
    return {
        'type': component_type,
        'template': filtered_template,  # Use filtered template
        'input_schema': input_schema,
        'outputs': filtered_outputs,  # Use filtered outputs
        'original_code': original_code,
        'selected_output': selected_output  # Pass through selected output for method detection
    }


def _generate_udf_creation_step(node_id: str, component_info: Dict[str, Any], dependencies: List[str]) -> Dict[str, Any]:
    """Generate a StepFlow step that creates a UDF blob for this component."""
    
    # Create the UDF blob data with only execution-critical information
    udf_data = {
        'input_schema': component_info['input_schema'],
        'code': component_info['original_code'],
        'component_type': component_info['type'],
        'outputs': component_info['outputs'],  # Include outputs metadata for execution method detection
        'template': component_info['template'],  # Include template for initialization
        'selected_output': component_info['selected_output']  # Include selected output for method detection
    }
    
    step = {
        'id': f'create_{node_id}_udf',
        'component': 'builtin://put_blob',
        'input': {
            'data': udf_data
        }
    }
    
    # Add dependencies if any
    if dependencies:
        step['depends_on'] = [f'create_{dep}_udf' for dep in dependencies]
    
    return step


def parse_langflow_to_stepflow_workflow(langflow_json: dict) -> List[Dict[str, Any]]:
    """
    Parse a Langflow JSON workflow and convert it to StepFlow workflow steps.
    
    Args:
        langflow_json: The Langflow workflow JSON structure
        
    Returns:
        List of StepFlow workflow steps that create UDF blobs for each component
    """
    data = langflow_json.get('data', {})
    nodes = data.get('nodes', [])
    edges = data.get('edges', [])
    
    # Build dependency graph from edges
    dependencies = _build_dependency_graph(edges)
    
    workflow_steps = []
    
    for node in nodes:
        node_data = node.get('data', {})
        node_id = node_data.get('id')
        node_type = node_data.get('type')
        
        # Skip note nodes and other non-component nodes
        if node_type in ['note', 'noteNode'] or not node_id:
            continue
            
        node_info = node_data.get('node', {})
        
        # Extract component information
        component_info = _extract_component_info(node_data, node_info)
        
        # Generate UDF creation step
        udf_step = _generate_udf_creation_step(node_id, component_info, dependencies.get(node_id, []))
        workflow_steps.append(udf_step)
    
    return workflow_steps


class LangflowUDFTranslator:
    """Updated translator that generates workflows compatible with langflow_component_server_udf_only.py"""
    
    def __init__(self):
        self.translated_steps = {}
        self.dependencies = {}
    
    def translate(self, langflow_json: Dict[str, Any]) -> Dict[str, Any]:
        """Translate Langflow JSON to StepFlow YAML that works with langflow_component_server_udf_only.py"""
        
        # Parse into UDF creation steps
        udf_steps = parse_langflow_to_stepflow_workflow(langflow_json)
        
        # Find input and output nodes
        nodes = langflow_json.get('data', {}).get('nodes', [])
        input_node = None
        output_node = None
        
        for node in nodes:
            node_type = node.get('data', {}).get('type')
            if node_type == 'ChatInput':
                input_node = node
            elif node_type == 'ChatOutput':
                output_node = node
        
        # Generate input schema
        input_schema = self._create_input_schema(input_node) if input_node else {
            'type': 'object',
            'properties': {
                'user_input': {'type': 'string', 'description': 'User input message'}
            },
            'required': ['user_input']
        }
        
        # Generate execution steps that use the UDF blobs
        execution_steps = self._create_execution_steps(langflow_json, udf_steps)
        
        # Combine UDF creation and execution steps, then sort to ensure proper dependency order
        all_steps = udf_steps + execution_steps
        
        # Sort execution steps by dependency order to avoid forward references
        all_steps = self._sort_steps_by_dependencies(all_steps)
        
        # Generate output mapping
        output_mapping = self._create_output_mapping(output_node, execution_steps) if output_node else {
            'result': {
                '$from': {'step': execution_steps[-1]['id'] if execution_steps else 'unknown'},
                'path': 'result'
            }
        }
        
        return {
            'name': langflow_json.get('name', 'Translated Langflow Workflow'),
            'description': f"Converted from Langflow using UDF execution. Original: {langflow_json.get('description', '')}",
            'input_schema': input_schema,
            'steps': all_steps,
            'output': output_mapping
        }
    
    def _create_input_schema(self, input_node: Dict[str, Any]) -> Dict[str, Any]:
        """Create workflow input schema from ChatInput node."""
        if not input_node:
            return {
                'type': 'object',
                'properties': {
                    'message': {'type': 'string', 'description': 'User input message'}
                },
                'required': ['message']
            }
        
        template = input_node.get('data', {}).get('node', {}).get('template', {})
        default_value = template.get('input_value', {}).get('value', '')
        
        return {
            'type': 'object',
            'properties': {
                'message': {
                    'type': 'string',
                    'description': 'User input message',
                    'default': default_value
                }
            },
            'required': ['message']
        }
    
    def _create_execution_steps(self, langflow_json: Dict[str, Any], udf_steps: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Create execution steps that use the UDF blobs."""
        execution_steps = []
        
        # Build dependency graph
        edges = langflow_json.get('data', {}).get('edges', [])
        dependencies = _build_dependency_graph(edges)
        
        # Create execution steps for each UDF
        for udf_step in udf_steps:
            # Extract the component info
            component_type = udf_step['input']['data']['component_type']
            node_id = udf_step['id'].replace('create_', '').replace('_udf', '')
            
            # Skip note nodes
            if component_type in ['unknown']:
                continue
            
            # Create execution step
            execution_step = {
                'id': f'execute_{node_id}',
                'component': 'langflow://udf_executor',
                'input': {
                    'blob_id': {
                        '$from': {'step': udf_step['id']},
                        'path': 'blob_id'
                    }
                }
            }
            
            # Add input data based on component type and dependencies
            if component_type == 'ChatInput':
                execution_step['input']['input'] = {
                    'input_value': {
                        '$from': {'input': 'message'}
                    }
                }
            else:
                # Handle dependencies from other components
                deps = dependencies.get(node_id, [])
                if deps:
                    execution_step['input']['input'] = {}
                    for dep in deps:
                        dep_execution_id = f'execute_{dep}'
                        # Map the dependency based on the edge connection
                        execution_step['input']['input']['input_value'] = {
                            '$from': {'step': dep_execution_id},
                            'path': 'result'
                        }
            
            # Add depends_on for execution order
            if 'depends_on' in udf_step:
                execution_step['depends_on'] = [udf_step['id']]
                # Also depend on execution of dependencies
                deps = dependencies.get(node_id, [])
                for dep in deps:
                    dep_execution_id = f'execute_{dep}'
                    if 'depends_on' not in execution_step:
                        execution_step['depends_on'] = []
                    execution_step['depends_on'].append(dep_execution_id)
            else:
                execution_step['depends_on'] = [udf_step['id']]
            
            execution_steps.append(execution_step)
        
        return execution_steps
    
    def _sort_steps_by_dependencies(self, steps: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Sort steps to ensure dependencies are defined before they're referenced."""
        sorted_steps = []
        step_dict = {step['id']: step for step in steps}
        processed = set()
        
        def add_step_with_deps(step_id: str):
            if step_id in processed or step_id not in step_dict:
                return
                
            step = step_dict[step_id]
            
            # First add all dependencies
            depends_on = step.get('depends_on', [])
            for dep in depends_on:
                add_step_with_deps(dep)
            
            # Check for $from references in inputs
            if 'input' in step:
                self._add_from_dependencies(step['input'], add_step_with_deps)
            
            # Add this step
            sorted_steps.append(step)
            processed.add(step_id)
        
        # Process all steps
        for step in steps:
            add_step_with_deps(step['id'])
        
        return sorted_steps
    
    def _add_from_dependencies(self, obj, add_step_func):
        """Recursively find and add $from step dependencies."""
        if isinstance(obj, dict):
            if '$from' in obj and 'step' in obj['$from']:
                add_step_func(obj['$from']['step'])
            else:
                for value in obj.values():
                    self._add_from_dependencies(value, add_step_func)
        elif isinstance(obj, list):
            for item in obj:
                self._add_from_dependencies(item, add_step_func)

    def _create_output_mapping(self, output_node: Dict[str, Any], execution_steps: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Create workflow output mapping from ChatOutput node."""
        if not execution_steps:
            return {'response': 'No execution steps found'}
        
        # Find the output execution step (usually the last one or ChatOutput)
        output_step = None
        for step in execution_steps:
            if 'ChatOutput' in step['id'] or 'output' in step['id'].lower():
                output_step = step
                break
        
        if not output_step:
            output_step = execution_steps[-1]  # Use last step as fallback
        
        return {
            'response': {
                '$from': {'step': output_step['id']},
                'path': 'result'
            }
        }


def main():
    """Main CLI interface."""
    parser = argparse.ArgumentParser(
        description='Convert Langflow JSON to StepFlow YAML using UDF execution',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
Examples:
  # Translate a Langflow JSON file
  python udf_translator_cli.py input.json output.yaml
  
  # Translate with pretty printing
  python udf_translator_cli.py input.json output.yaml --pretty
  
  # Analyze a Langflow JSON structure
  python udf_translator_cli.py input.json --analyze-only
        '''
    )
    
    parser.add_argument('input_file', help='Input Langflow JSON file')
    parser.add_argument('output_file', nargs='?', help='Output StepFlow YAML file')
    parser.add_argument('--pretty', action='store_true', help='Pretty print the output')
    parser.add_argument('--analyze-only', action='store_true', help='Only analyze the structure, don\'t translate')
    
    args = parser.parse_args()
    
    # Check if input file exists
    if not Path(args.input_file).exists():
        print(f"Error: Input file '{args.input_file}' not found")
        return 1
    
    # Load Langflow JSON
    try:
        with open(args.input_file, 'r') as f:
            langflow_data = json.load(f)
    except Exception as e:
        print(f"Error loading Langflow JSON: {e}")
        return 1
    
    # If analyze only, just print structure
    if args.analyze_only:
        analyze_langflow_structure(langflow_data)
        return 0
    
    # Check if output file specified
    if not args.output_file:
        print("Error: Output file required (unless using --analyze-only)")
        return 1
    
    # Create translator and translate
    translator = LangflowUDFTranslator()
    
    try:
        print(f"Translating {args.input_file} to {args.output_file}...")
        stepflow_data = translator.translate(langflow_data)
        
        # Save the result
        with open(args.output_file, 'w') as f:
            yaml.dump(stepflow_data, f, default_flow_style=False, indent=2, sort_keys=False)
        
        print(f"✅ Translation successful!")
        print(f"Output saved to: {args.output_file}")
        
        # Print statistics
        print(f"\nTranslation Statistics:")
        print(f"- Original nodes: {len(langflow_data.get('data', {}).get('nodes', []))}")
        print(f"- Translated steps: {len(stepflow_data.get('steps', []))}")
        print(f"- Has input schema: {stepflow_data.get('input_schema') is not None}")
        print(f"- Has output mapping: {stepflow_data.get('output') is not None}")
        
        if args.pretty:
            print(f"\n=== Generated StepFlow YAML ===")
            print(yaml.dump(stepflow_data, default_flow_style=False, indent=2))
        
        return 0
        
    except Exception as e:
        print(f"❌ Translation failed: {e}")
        import traceback
        traceback.print_exc()
        return 1

def analyze_langflow_structure(langflow_data):
    """Analyze the Langflow JSON structure."""
    
    nodes = langflow_data.get('data', {}).get('nodes', [])
    edges = langflow_data.get('data', {}).get('edges', [])
    
    print("=== Langflow Structure Analysis ===")
    print(f"Workflow name: {langflow_data.get('name', 'Unnamed')}")
    print(f"Total nodes: {len(nodes)}")
    print(f"Total edges: {len(edges)}")
    
    print("\nNode Details:")
    for i, node in enumerate(nodes, 1):
        node_type = node.get('data', {}).get('type', 'Unknown')
        node_id = node.get('id', 'Unknown')
        
        # Check if it has code
        template = node.get('data', {}).get('node', {}).get('template', {})
        has_code = 'code' in template and template.get('code', {}).get('value', '') != ''
        
        # Check output types
        outputs = node.get('data', {}).get('node', {}).get('outputs', [])
        output_types = outputs[0].get('types', []) if outputs else []
        
        # Check base classes
        base_classes = node.get('data', {}).get('node', {}).get('base_classes', [])
        
        print(f"  {i}. {node_type} (ID: {node_id})")
        print(f"     Has code: {has_code}")
        print(f"     Output types: {output_types}")
        print(f"     Base classes: {base_classes}")
        
        if has_code:
            code_lines = template.get('code', {}).get('value', '').split('\n')
            print(f"     Code lines: {len(code_lines)}")
            
            # Show class definition if found
            for line in code_lines:
                if line.strip().startswith('class '):
                    class_name = line.strip().split('class ')[1].split('(')[0].split(':')[0]
                    print(f"     Class: {class_name}")
                    break
        print()
    
    print("Edge Connections:")
    for i, edge in enumerate(edges, 1):
        source_id = edge.get('source', 'Unknown')
        target_id = edge.get('target', 'Unknown')
        
        # Get source and target handles
        source_handle = edge.get('data', {}).get('sourceHandle', {})
        target_handle = edge.get('data', {}).get('targetHandle', {})
        
        source_name = source_handle.get('name', 'unknown') if isinstance(source_handle, dict) else 'unknown'
        target_field = target_handle.get('fieldName', 'unknown') if isinstance(target_handle, dict) else 'unknown'
        
        print(f"  {i}. {source_id}[{source_name}] → {target_id}[{target_field}]")

if __name__ == "__main__":
    exit(main()) 