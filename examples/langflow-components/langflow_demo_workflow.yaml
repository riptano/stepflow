name: "Langflow Components Demo"
description: "Demonstrates integration with actual Langflow components like OpenAIChatModel"

input_schema:
  type: object
  properties:
    user_message:
      type: string
      description: "User's message for the AI assistant"
      default: "Explain quantum computing in simple terms"
    system_prompt:
      type: string
      description: "System prompt template with variables"
      default: "You are a helpful {role} assistant. Your expertise is in {domain}. Please provide clear, {style} explanations."
    role:
      type: string
      description: "Role for the AI assistant"
      default: "technical"
    domain:
      type: string
      description: "Domain of expertise"
      default: "computer science"
    style:
      type: string
      description: "Communication style"
      default: "concise"

steps:
  # Step 1: Format the system prompt using native Langflow PromptComponent
  - id: format_system_prompt
    component: langflow://prompt_formatter
    input:
      template: { $from: { workflow: input }, path: "system_prompt" }
      variables:
        role: { $from: { workflow: input }, path: "role" }
        domain: { $from: { workflow: input }, path: "domain" }
        style: { $from: { workflow: input }, path: "style" }

  # Step 2: Create a native Langflow Message object
  - id: create_system_message
    component: langflow://create_message
    input:
      text: { $from: { step: format_system_prompt }, path: "formatted_prompt" }
      sender: "system"
      sender_name: "system"

  # Step 3: Create user message
  - id: create_user_message
    component: langflow://create_message
    input:
      text: { $from: { workflow: input }, path: "user_message" }
      sender: "user"
      sender_name: "user"

  # Step 4: Call OpenAI using native Langflow OpenAIChatModel
  - id: openai_chat_response
    component: langflow://openai_chat
    input:
      messages: 
        - { $from: { step: create_system_message } }
        - { $from: { step: create_user_message } }
      model: "gpt-4o-mini"
      temperature: 0.3
      max_tokens: 500
      api_key: null  # Will use OPENAI_API_KEY environment variable

  # Step 5: Echo component to demonstrate native type handling
  - id: echo_test
    component: langflow://echo_component
    input:
      original_response: { $from: { step: openai_chat_response } }
      formatted_prompt: { $from: { step: format_system_prompt } }
      system_message: { $from: { step: create_system_message } }
      user_message: { $from: { step: create_user_message } }

output:
  # Native Langflow results - these are the actual Data/Message objects
  openai_response: { $from: { step: openai_chat_response } }
  formatted_prompt: { $from: { step: format_system_prompt } }
  system_message: { $from: { step: create_system_message } }
  user_message: { $from: { step: create_user_message } }
  echo_result: { $from: { step: echo_test } }