schema: https://stepflow.org/schemas/v1/flow.json
name: "Production AI Pipeline"
description: |
  Demonstrates production-ready AI model serving with:
  1. Resource-aware model routing (CPU vs GPU models)
  2. Health checks and monitoring
  3. Batch processing for efficiency
  4. Multi-modal AI processing (text + vision)

  This workflow showcases how Stepflow enables:
  - Independent scaling of different model types
  - Resource optimization through intelligent routing
  - Production monitoring and observability
  - Graceful error handling and fallbacks

input_schema:
  type: object
  properties:
    # User content to process
    user_text:
      type: string
      description: "Text content to analyze"
    user_image:
      type: string
      description: "Base64 encoded image to classify"

    # Processing configuration
    processing_mode:
      type: string
      enum: ["fast", "accurate", "batch"]
      default: "fast"
    batch_size:
      type: integer
      default: 4
      description: "Batch size for processing"

    # Model selection preferences
    prefer_gpu:
      type: boolean
      default: false
      description: "Prefer GPU models when available"
  required: ["user_text"]

output_schema:
  type: object
  properties:
    processing_summary:
      type: object
    text_analysis:
      type: object
    image_analysis:
      type: object

steps:
  # Step 1: Health check both model servers
  - id: text_health_check
    component: /models/text/model_health_check
    input:
      detailed: true
    on_error:
      action: fail
      message: "Text model server unavailable"

  - id: vision_health_check
    component: /models/vision/vision_health_check
    input:
      detailed: true
    on_error:
      action: skip  # Vision is optional

  # Step 2: Store processing configuration for later use
  - id: processing_config_udf
    component: /put_blob
    input:
      data:
        input_schema:
          type: object
          properties:
            prefer_gpu:
              type: boolean
            processing_mode:
              type: string
        code: |
          return {
              "prefer_gpu": input.prefer_gpu,
              "processing_mode": input.processing_mode,
              "suggested_text_model": "distilbert-sentiment",
          }
      blob_type: "data"
  - id: processing_config
    component: /python/udf
    input:
      blob_id: { $from: { step: processing_config_udf }, path: "blob_id" }
      input:
        prefer_gpu: { $from: { workflow: input }, path: "prefer_gpu" }
        processing_mode: { $from: { workflow: input }, path: "processing_mode" }

  # Step 3: Process text content with sentiment analysis
  - id: sentiment_analysis_udf
    component: /put_blob
    input:
      data:
        input_schema:
          type: object
          properties:
            user_text:
              type: string
            suggested_text_model:
              type: string
        code: |
          if not input.user_text or len(input.user_text.strip()) == 0:
              raise SkipStep("No text provided for sentiment analysis")
          
          # Return the configuration for the actual sentiment analysis step
          return {
              "text": input.user_text,
              "model_name": input.suggested_text_model
          }
      blob_type: "data"
  - id: sentiment_analysis_config
    component: /python/udf
    input:
      blob_id: { $from: { step: sentiment_analysis_udf }, path: "blob_id" }
      input:
        user_text: { $from: { workflow: input }, path: "user_text" }
        suggested_text_model: { $from: { step: processing_config }, path: "suggested_text_model" }
  
  - id: sentiment_analysis
    component: /models/text/analyze_sentiment
    input:
      text: { $from: { step: sentiment_analysis_config }, path: "text" }
      model_name: { $from: { step: sentiment_analysis_config }, path: "model_name" }

  # Step 4: Generate text response based on sentiment
  - id: text_generation_udf
    component: /put_blob
    input:
      data:
        input_schema:
          type: object
          properties:
            processing_mode:
              type: string
            user_text:
              type: string
            sentiment_analysis:
              type: object
        code: |
          if input.processing_mode != "fast":
              raise SkipStep("Text generation only runs in fast processing mode")
          
          # Build the prompt with sentiment context
          sentiment = input.sentiment_analysis
          prompt = f"Based on the sentiment analysis ({sentiment['label']} with confidence {sentiment['score']}), generate a thoughtful response to: {input.user_text}"
          
          return {
              "prompt": prompt,
              "model_name": "gpt2-small",
              "max_length": 150,
              "temperature": 0.7
          }
      blob_type: "data"
  - id: text_generation_config
    component: /python/udf
    input:
      blob_id: { $from: { step: text_generation_udf }, path: "blob_id" }
      input:
        processing_mode: { $from: { step: processing_config }, path: "processing_mode" }
        user_text: { $from: { workflow: input }, path: "user_text" }
        sentiment_analysis: { $from: { step: sentiment_analysis } }

  - id: text_generation
    component: /models/text/generate_text
    input:
      prompt: { $from: { step: text_generation_config }, path: "prompt" }
      model_name: { $from: { step: text_generation_config }, path: "model_name" }
      max_length: { $from: { step: text_generation_config }, path: "max_length" }
      temperature: { $from: { step: text_generation_config }, path: "temperature" }

  # Step 5: Process image if provided
  - id: image_classification_udf
    component: /put_blob
    input:
      data:
        input_schema:
          type: object
          properties:
            user_image:
              type: string
        code: |
          image_data = input.get("user_image", "") or ""
          if not image_data or len(image_data.strip()) == 0:
              raise SkipStep("No image provided for classification")
          
          return {
              "image_data": image_data,
              "model_name": "resnet50",  # Default vision model
              "top_k": 5
          }
      blob_type: "data"
  - id: image_classification_config
    component: /python/udf
    input:
      blob_id: { $from: { step: image_classification_udf }, path: "blob_id" }
      input:
        user_image: { $from: { workflow: input }, path: "user_image" }

  - id: image_classification
    component: /models/vision/classify_image
    input:
      image_data: { $from: { step: image_classification_config }, path: "image_data" }
      model_name: { $from: { step: image_classification_config }, path: "model_name" }
      top_k: { $from: { step: image_classification_config }, path: "top_k" }
    on_error:
      action: skip
      message: "Image processing failed, continuing without image analysis"

  # Step 6: Get image metrics and recommendations
  - id: image_analysis_udf
    component: /put_blob
    input:
      data:
        input_schema:
          type: object
          properties:
            user_image:
              type: string
        code: |
          image_data = input.get("user_image", "") or ""
          if not image_data or len(image_data.strip()) == 0:
              raise SkipStep("No image provided for metrics analysis")
          
          return {"image_data": image_data}
      blob_type: "data"
  - id: image_analysis_config
    component: /python/udf
    input:
      blob_id: { $from: { step: image_analysis_udf }, path: "blob_id" }
      input:
        user_image: { $from: { workflow: input }, path: "user_image" }

  - id: image_analysis
    component: /models/vision/analyze_image_metrics
    input:
      image_data: { $from: { step: image_analysis_config }, path: "image_data" }

  # Step 7: Demonstrate batch processing capabilities
  - id: batch_demo_udf
    component: /put_blob
    input:
      data:
        input_schema:
          type: object
          properties:
            processing_mode:
              type: string
            user_text:
              type: string
            batch_size:
              type: integer
        code: |
          if input.processing_mode != "batch":
              raise SkipStep("Batch processing only runs in batch processing mode")
          
          return {
              "texts": [
                  input.user_text,
                  "Additional sample text for batch processing",
                  "Another example to show batching efficiency"
              ],
              "model_name": "distilbert-sentiment",
              "task": "sentiment",
              "batch_size": input.batch_size
          }
      blob_type: "data"
  - id: batch_demo_config
    component: /python/udf
    input:
      blob_id: { $from: { step: batch_demo_udf }, path: "blob_id" }
      input:
        processing_mode: { $from: { step: processing_config }, path: "processing_mode" }
        user_text: { $from: { workflow: input }, path: "user_text" }
        batch_size: { $from: { workflow: input }, path: "batch_size" }

  - id: batch_demo
    component: /models/text/batch_process_text
    input:
      texts: { $from: { step: batch_demo_config }, path: "texts" }
      model_name: { $from: { step: batch_demo_config }, path: "model_name" }
      task: { $from: { step: batch_demo_config }, path: "task" }
      batch_size: { $from: { step: batch_demo_config }, path: "batch_size" }

  # Step 8: Compile comprehensive results with performance metrics
  - id: final_results_udf
    component: /put_blob
    input:
      data:
        input_schema:
          type: object
          properties:
            processing_config:
              type: object
            sentiment_analysis:
              type: object
            text_generation:
              type: object
            image_classification:
              type: object
            image_analysis:
              type: object
            batch_demo:
              type: object
        code: |
            processing_config = input.get("processing_config", {})
            sentiment_analysis = input.get("sentiment_analysis", None)
            text_generation = input.get("text_generation", None)
            image_classification = input.get("image_classification", None)
            image_analysis = input.get("image_analysis", None)
            batch_demo = input.get("batch_demo", None)
            
            return {
              "processing_summary": {
                "mode": processing_config.get("processing_mode", "unknown"),
                "text_processed": sentiment_analysis is not None,
                "image_processed": image_classification is not None,
                "batch_processing_used": batch_demo is not None,
                "total_processing_time_ms": (
                  (sentiment_analysis.get("inference_time", {}).get("ms", 0) if sentiment_analysis else 0) +
                  (text_generation.get("generation_time_ms", 0) if text_generation else 0) +
                  (image_classification.get("inference_time_ms", 0) if image_classification else 0)
                )
              },
              "text_analysis": {
                "sentiment": sentiment_analysis.get("label") if sentiment_analysis else None,
                "confidence": sentiment_analysis.get("score") if sentiment_analysis else None,
                "model_used": sentiment_analysis.get("model_used") if sentiment_analysis else None,
                "generated_response": text_generation.get("generated_text") if text_generation else None
              },
              "image_analysis": {
                "classifications": image_classification.get("predictions") if image_classification else None,
                "image_properties": {
                  "dimensions": [image_analysis.get("width", 0), image_analysis.get("height", 0)],
                  "format": image_analysis.get("format"),
                  "size_bytes": image_analysis.get("size_bytes"),
                  "recommended_model": image_analysis.get("recommended_model")
                } if image_analysis else None,
                "resource_tier_used": image_classification.get("resource_tier") if image_classification else None
              },
            }
      blob_type: "data"

  - id: final_results
    component: /python/udf
    input:
      blob_id: { $from: { step: final_results_udf }, path: "blob_id" }
      input:
        processing_config:
          $from: { step: processing_config }
          onSkip:
            action: useDefault
        sentiment_analysis:
          $from: { step: sentiment_analysis }
          onSkip:
            action: useDefault
        batch_demo:
          $from: { step: batch_demo }
          onSkip:
            action: useDefault
        text_generation:
          $from: { step: text_generation }
          onSkip:
            action: useDefault
        image_classification:
          $from: { step: image_classification }
          onSkip:
            action: useDefault
        image_analysis:
          $from: { step: image_analysis }
          onSkip:
            action: useDefault


output: { $from: { step: final_results } }